import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œå›¾å½¢æ ·å¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")

# 1. åŠ è½½ç‰¹å¾æ•°æ®
print("ğŸ“‚ åŠ è½½ç‰¹å¾æ•°æ®...")
df = pd.read_csv('HDOs_with_features.csv')
print(f"æ•°æ®é›†å½¢çŠ¶: {df.shape}")
print(f"ç‰¹å¾æ•°é‡: {df.shape[1] - 12} ä¸ªæ•°å€¼ç‰¹å¾")  # å‡å»åŸå§‹12åˆ—

# 2. æ£€æŸ¥ç¼ºå¤±å€¼
print("\nğŸ” æ£€æŸ¥ç¼ºå¤±å€¼æƒ…å†µ:")
missing_data = df.isnull().sum()
missing_percent = (missing_data / len(df)) * 100
missing_df = pd.DataFrame({
    'ç¼ºå¤±æ•°é‡': missing_data,
    'ç¼ºå¤±æ¯”ä¾‹%': missing_percent
})
# åªæ˜¾ç¤ºæœ‰ç¼ºå¤±å€¼çš„åˆ—
missing_with_values = missing_df[missing_df['ç¼ºå¤±æ•°é‡'] > 0]
if len(missing_with_values) > 0:
    print(missing_with_values.sort_values('ç¼ºå¤±æ•°é‡', ascending=False).head(10))
else:
    print("âœ… æ²¡æœ‰ç¼ºå¤±å€¼ï¼")

# 3. å¤„ç†ç¼ºå¤±å€¼ï¼ˆç”¨ä¸­ä½æ•°å¡«å……æ•°å€¼åˆ—ï¼‰
print("\nğŸ”„ å¤„ç†ç¼ºå¤±å€¼...")
numeric_cols = df.select_dtypes(include=[np.number]).columns
df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())
print("âœ… ç¼ºå¤±å€¼å·²ç”¨ä¸­ä½æ•°å¡«å……")

# 4. ç‰¹å¾åˆ†å¸ƒå¯è§†åŒ–
print("\nğŸ“ˆ ç»˜åˆ¶ç‰¹å¾åˆ†å¸ƒå›¾...")
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
fig.suptitle('å…³é”®ç‰¹å¾åˆ†å¸ƒ', fontsize=16)

# é€‰æ‹©å‡ ä¸ªå…³é”®ç‰¹å¾å±•ç¤º
key_features = ['length', 'molecular_weight', 'isoelectric_point', 
                'gravy', 'instability_index', 'helix_fraction']

for idx, feature in enumerate(key_features):
    if feature in df.columns:
        ax = axes[idx//3, idx%3]
        ax.hist(df[feature].dropna(), bins=30, edgecolor='black', alpha=0.7)
        ax.set_xlabel(feature)
        ax.set_ylabel('é¢‘æ•°')
        ax.set_title(f'{feature} åˆ†å¸ƒ')

plt.tight_layout()
plt.savefig('feature_distributions.png', dpi=300, bbox_inches='tight')
print("âœ… ç‰¹å¾åˆ†å¸ƒå›¾å·²ä¿å­˜ä¸º 'feature_distributions.png'")

# 5. ç‰¹å¾ç›¸å…³æ€§åˆ†æ
print("\nğŸ“Š è®¡ç®—ç‰¹å¾ç›¸å…³æ€§...")
# é€‰æ‹©æ•°å€¼ç‰¹å¾è¿›è¡Œç›¸å…³æ€§åˆ†æï¼ˆæ’é™¤éæ•°å€¼åˆ—å’ŒIDåˆ—ï¼‰
exclude_cols = ['Entry', 'Entry Name', 'Protein names', 'Gene Names', 
                'Organism', 'Sequence', 'EC number', 'Function [CC]', 
                'Cofactor', 'Keywords', 'Reviewed']
numeric_features = [col for col in df.columns if col not in exclude_cols]

if len(numeric_features) > 0:
    corr_matrix = df[numeric_features].corr()
    
    # ç»˜åˆ¶ç›¸å…³æ€§çƒ­å›¾ï¼ˆåªæ˜¾ç¤ºå‰20ä¸ªç‰¹å¾çš„ç›¸å…³æ€§ï¼Œé¿å…å›¾åƒå¤ªå¯†é›†ï¼‰
    features_for_heatmap = numeric_features[:20]
    corr_subset = df[features_for_heatmap].corr()
    
    plt.figure(figsize=(12, 10))
    sns.heatmap(corr_subset, annot=True, fmt='.2f', cmap='coolwarm', 
                center=0, square=True, linewidths=0.5)
    plt.title('ç‰¹å¾ç›¸å…³æ€§çƒ­å›¾ (å‰20ä¸ªç‰¹å¾)')
    plt.tight_layout()
    plt.savefig('feature_correlation.png', dpi=300, bbox_inches='tight')
    print("âœ… ç›¸å…³æ€§çƒ­å›¾å·²ä¿å­˜ä¸º 'feature_correlation.png'")
    
    # æ‰¾å‡ºé«˜åº¦ç›¸å…³çš„ç‰¹å¾å¯¹
    print("\nğŸ”— é«˜åº¦ç›¸å…³çš„ç‰¹å¾å¯¹ (|ç›¸å…³æ€§| > 0.8):")
    high_corr_pairs = []
    for i in range(len(corr_matrix.columns)):
        for j in range(i+1, len(corr_matrix.columns)):
            if abs(corr_matrix.iloc[i, j]) > 0.8:
                high_corr_pairs.append((
                    corr_matrix.columns[i], 
                    corr_matrix.columns[j], 
                    corr_matrix.iloc[i, j]
                ))
    
    if high_corr_pairs:
        for pair in high_corr_pairs[:10]:  # åªæ˜¾ç¤ºå‰10å¯¹
            print(f"  {pair[0]} ä¸ {pair[1]}: {pair[2]:.3f}")
    else:
        print("  æ²¡æœ‰é«˜åº¦ç›¸å…³çš„ç‰¹å¾å¯¹")

# 6. åŸºäºECç¼–å·çš„åŠŸèƒ½åˆ†ç±»æ¢ç´¢
print("\nğŸ”¬ åŸºäºECç¼–å·çš„åŠŸèƒ½åˆ†æ...")
if 'EC number' in df.columns:
    # æå–ECç¼–å·çš„ç¬¬ä¸€éƒ¨åˆ†ï¼ˆå¤§ç±»ï¼‰
    df['EC_class'] = df['EC number'].astype(str).str.extract(r'^(\d+)\.')
    
    ec_counts = df['EC_class'].value_counts()
    print("ECç¼–å·å¤§ç±»åˆ†å¸ƒ:")
    for ec_class, count in ec_counts.items():
        if pd.notna(ec_class):
            ec_names = {
                '1': 'æ°§åŒ–è¿˜åŸé…¶',
                '2': 'è½¬ç§»é…¶', 
                '3': 'æ°´è§£é…¶',
                '4': 'è£‚åˆé…¶',
                '5': 'å¼‚æ„é…¶',
                '6': 'è¿æ¥é…¶'
            }
            name = ec_names.get(ec_class, 'æœªçŸ¥')
            print(f"  EC {ec_class}.x.x.x ({name}): {count} æ¡")

# 7. ä¿å­˜å¤„ç†åçš„æ•°æ®
output_file = 'HDOs_processed_ready.csv'
# ç§»é™¤åŸå§‹çš„å¤§æ–‡æœ¬åˆ—ï¼Œä¿ç•™ç‰¹å¾å’Œå…³é”®ä¿¡æ¯
cols_to_keep = ['Entry', 'Protein names', 'EC number'] + numeric_features
df_clean = df[cols_to_keep].copy()
df_clean.to_csv(output_file, index=False)

print(f"\nğŸ‰ æ•°æ®æ¢ç´¢å®Œæˆï¼")
print(f"âœ… å¤„ç†åçš„æ•°æ®å·²ä¿å­˜: {output_file}")
print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜")
print(f"\nğŸ“‹ ä¸‹ä¸€æ­¥å»ºè®®:")
print("1. æ£€æŸ¥ 'feature_distributions.png' äº†è§£ç‰¹å¾åˆ†å¸ƒ")
print("2. æŸ¥çœ‹ 'feature_correlation.png' è¯†åˆ«ç›¸å…³ç‰¹å¾")
print("3. ä½¿ç”¨ 'HDOs_processed_ready.csv' è¿›è¡Œæœºå™¨å­¦ä¹ å»ºæ¨¡")

# æ˜¾ç¤ºå‰å‡ è¡Œå¤„ç†åçš„æ•°æ®
print(f"\nğŸ“„ å¤„ç†åçš„æ•°æ®é¢„è§ˆ:")
print(df_clean[['Entry', 'Protein names', 'length', 'molecular_weight', 'isoelectric_point']].head())